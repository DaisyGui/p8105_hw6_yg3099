---
title: "p8105_hw6_yg3099"
author: "daisy_gui"
date: "2025-12-01"
output: github_document
---

```{r}
library(ggplot2)
library(tidyverse)
library(broom)
library(purrr)
library(p8105.datasets)
```

## Problem 1

First, data is read from csv file.

```{r}
homi_raw = read_csv("data/homicide-data.csv")
```

Then clean the data. 

```{r}
homi_df =
  homi_raw %>%
  mutate(
    city_state = str_c(city, state, sep = ", "), # city_state variable
    resolved = as.numeric(disposition == "Closed by arrest"), # resolved variable
    victim_age = as.numeric(victim_age) # ensure numeric victim age
  ) %>%
  
  # omit cities with missing or incorrect data
  filter(!(city_state %in% c("Dallas, TX",
                             "Phoenix, AZ",
                             "Kansas City, MO",
                             "Tulsa, AL"))) |> 

  # limit victim race to white or black
  filter(victim_race %in% c("White", "Black")) |>

  # set baselines
  mutate(
    victim_race = fct_relevel(victim_race, "White"),
    victim_sex = fct_relevel(victim_sex, "Female")
  )
```

Data is cleaned by creating a city_state variable and a variable on whether the homicide is solved. Cities with missing or incorrect data are omitted. The analysis is limited to white or black victims. And victim_age is changed from character into numeric. 

Now perform logistic regression on predictors of whether cases are resolved in Baltimore.

```{r}
# select Baltimore city
balti_df =
  homi_df |> 
  filter(city_state == "Baltimore, MD") # select Baltimore city

# logistic regression
balti_log =
  balti_df |> 
  glm(resolved ~ victim_age + victim_sex + victim_race,
      data = _,
      family = binomial())

# tidy logistic regression result and calculate OR
tidy_balti = 
  balti_log |> 
  broom::tidy(conf.int = TRUE) |> 
  mutate(OR = exp(estimate),
         OR_low = exp(conf.low),
         OR_high = exp(conf.high))

balti_sex = 
  tidy_balti |>
  filter(term == "victim_sexMale") |> 
  select(term, OR, OR_low, OR_high)
```

The adjusted odds ratio comparing male victims to female victims is 0.426 with 95% CI: 0.324,0.558, when holding age and race constant.

After adjusting for victim age and race, male homicide cases have 0.43 times the odds of being solved compared to female cases.

Since the 95% confidence interval of odd ratio does not include 1, it is statistically significant that homicide cases in Baltimore involving male victims have lower odds of being solved compared to cases involving female victims.

Now calculate odd ratio and CIs on all cities. 

```{r}
# glm on all cities
cities_log =
  homi_df |> 
  nest(city_row = -city_state) |> 
  mutate(
    models = map(
      city_row,
      \(df) glm(
        resolved ~ victim_age + victim_sex + victim_race,
        data = df,
        family = binomial()
      )
    ),
    results = map(
      models,
      \(mod) broom::tidy(mod, conf.int = TRUE)
    )
  ) |>
  select(-city_row, -models) |>
  unnest(results)

# odd ratio and filter sex
cities_OR =
  cities_log |> 
  filter(term == "victim_sexMale") |> 
  mutate(
    OR      = exp(estimate),
    OR_low  = exp(conf.low),
    OR_high = exp(conf.high)
  )
```

A plot on ORs and CIs of solving homicides comparing male victims to female victims for each city can be created. 

```{r}
cities_OR |> 
  ggplot(aes(x = reorder(city_state, OR), y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = OR_low, ymax = OR_high)) +
  coord_flip() +
  labs(
    x = "Cities",
    y = "Adjusted Odd Ratio",
    title = "Odds ratio of solving homicides comparing male vs female victims"
  ) 
```

Across the 50 cities, most adjusted odds ratios lie below 1 and confidence intervals do not cross 1, indicating that homicide cases involving male victims are generally less likely to be solved than those involving female victims after adjusting for age and race.

A few cities show ORs above 1, but their confidence intervals are wide, with lower bound of CI lower than 1, reflecting limited sample sizes or significance.

## Problem 2 

Import and clean data from package and set seed. 

```{r}
set.seed(1)

data("weather_df")

weather_clean = 
  weather_df |> 
  select(tmax, tmin, prcp) |> 
  drop_na()
```

Observations with NA are omitted and only reponse and predictors are kept as variables. 

Define bootstrapping dunction. 

```{r}
boot_func = function(df) {
  sample_frac(df, replace = TRUE)
}
```

Save 5000 bootstrap samples. 

```{r}
n_boot = 5000

boot_straps = 
  tibble(strap_number = 1:n_boot) |>
  mutate(
    strap_sample = map(strap_number, \(i) boot_func(weather_clean))
  )

boot_straps
```

