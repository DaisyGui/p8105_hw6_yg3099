p8105_hw6_yg3099
================
daisy_gui
2025-12-01

``` r
library(ggplot2)
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ lubridate 1.9.4     ✔ tibble    3.2.1
    ## ✔ purrr     1.1.0     ✔ tidyr     1.3.1
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(broom)
library(purrr)
library(p8105.datasets)
```

## Problem 1

First, data is read from csv file.

``` r
homi_raw = read_csv("data/homicide-data.csv")
```

    ## Rows: 52179 Columns: 12
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (9): uid, victim_last, victim_first, victim_race, victim_age, victim_sex...
    ## dbl (3): reported_date, lat, lon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Then clean the data.

``` r
homi_df =
  homi_raw %>%
  mutate(
    city_state = str_c(city, state, sep = ", "), # city_state variable
    resolved = as.numeric(disposition == "Closed by arrest"), # resolved variable
    victim_age = as.numeric(victim_age) # ensure numeric victim age
  ) %>%
  
  # omit cities with missing or incorrect data
  filter(!(city_state %in% c("Dallas, TX",
                             "Phoenix, AZ",
                             "Kansas City, MO",
                             "Tulsa, AL"))) |> 

  # limit victim race to white or black
  filter(victim_race %in% c("White", "Black")) |>

  # set baselines
  mutate(
    victim_race = fct_relevel(victim_race, "White"),
    victim_sex = fct_relevel(victim_sex, "Female")
  )
```

    ## Warning: There was 1 warning in `mutate()`.
    ## ℹ In argument: `victim_age = as.numeric(victim_age)`.
    ## Caused by warning:
    ## ! NAs introduced by coercion

Data is cleaned by creating a city_state variable and a variable on
whether the homicide is solved. Cities with missing or incorrect data
are omitted. The analysis is limited to white or black victims. And
victim_age is changed from character into numeric.

Now perform logistic regression on predictors of whether cases are
resolved in Baltimore.

``` r
# select Baltimore city
balti_df =
  homi_df |> 
  filter(city_state == "Baltimore, MD") # select Baltimore city

# logistic regression
balti_log =
  balti_df |> 
  glm(resolved ~ victim_age + victim_sex + victim_race,
      data = _,
      family = binomial())

# tidy logistic regression result and calculate OR
tidy_balti = 
  balti_log |> 
  broom::tidy(conf.int = TRUE) |> 
  mutate(OR = exp(estimate),
         OR_low = exp(conf.low),
         OR_high = exp(conf.high))

balti_sex = 
  tidy_balti |>
  filter(term == "victim_sexMale") |> 
  select(term, OR, OR_low, OR_high)
```

The adjusted odds ratio comparing male victims to female victims is
0.426 with 95% CI: 0.324,0.558, when holding age and race constant.

After adjusting for victim age and race, male homicide cases have 0.43
times the odds of being solved compared to female cases.

Since the 95% confidence interval of odd ratio does not include 1, it is
statistically significant that homicide cases in Baltimore involving
male victims have lower odds of being solved compared to cases involving
female victims.

Now calculate odd ratio and CIs on all cities.

``` r
# glm on all cities
cities_log =
  homi_df |> 
  nest(city_row = -city_state) |> 
  mutate(
    models = map(
      city_row,
      \(df) glm(
        resolved ~ victim_age + victim_sex + victim_race,
        data = df,
        family = binomial()
      )
    ),
    results = map(
      models,
      \(mod) broom::tidy(mod, conf.int = TRUE)
    )
  ) |>
  select(-city_row, -models) |>
  unnest(results)
```

    ## Warning: There were 43 warnings in `mutate()`.
    ## The first warning was:
    ## ℹ In argument: `results = map(models, function(mod) broom::tidy(mod, conf.int =
    ##   TRUE))`.
    ## Caused by warning:
    ## ! glm.fit: fitted probabilities numerically 0 or 1 occurred
    ## ℹ Run `dplyr::last_dplyr_warnings()` to see the 42 remaining warnings.

``` r
# odd ratio and filter sex
cities_OR =
  cities_log |> 
  filter(term == "victim_sexMale") |> 
  mutate(
    OR      = exp(estimate),
    OR_low  = exp(conf.low),
    OR_high = exp(conf.high)
  )
```

A plot on ORs and CIs of solving homicides comparing male victims to
female victims for each city can be created.

``` r
cities_OR |> 
  ggplot(aes(x = reorder(city_state, OR), y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = OR_low, ymax = OR_high)) +
  coord_flip() +
  labs(
    x = "Cities",
    y = "Adjusted Odd Ratio",
    title = "Odds ratio of solving homicides comparing male vs female victims"
  ) 
```

![](p8105_hw6_yg3099_files/figure-gfm/unnamed-chunk-6-1.png)<!-- -->

Across the 50 cities, most adjusted odds ratios lie below 1 and
confidence intervals do not cross 1, indicating that homicide cases
involving male victims are generally less likely to be solved than those
involving female victims after adjusting for age and race.

A few cities show ORs above 1, but their confidence intervals are wide,
with lower bound of CI lower than 1, reflecting limited sample sizes or
significance.

## Problem 2

Import and clean data from package and set seed.

``` r
set.seed(1)

data("weather_df")

weather_clean = 
  weather_df |> 
  select(tmax, tmin, prcp) |> 
  drop_na()
```

Observations with NA are omitted and only reponse and predictors are
kept as variables.

Define bootstrapping dunction.

``` r
boot_func = function(df) {
  sample_frac(df, replace = TRUE)
}
```

Save 5000 bootstrap samples.

``` r
n_boot = 5000

boot_straps = 
  tibble(strap_number = 1:n_boot) |>
  mutate(
    strap_sample = map(strap_number, \(i) boot_func(weather_clean))
  )

boot_straps
```

    ## # A tibble: 5,000 × 2
    ##    strap_number strap_sample        
    ##           <int> <list>              
    ##  1            1 <tibble [2,171 × 3]>
    ##  2            2 <tibble [2,171 × 3]>
    ##  3            3 <tibble [2,171 × 3]>
    ##  4            4 <tibble [2,171 × 3]>
    ##  5            5 <tibble [2,171 × 3]>
    ##  6            6 <tibble [2,171 × 3]>
    ##  7            7 <tibble [2,171 × 3]>
    ##  8            8 <tibble [2,171 × 3]>
    ##  9            9 <tibble [2,171 × 3]>
    ## 10           10 <tibble [2,171 × 3]>
    ## # ℹ 4,990 more rows

Linear regression on each bootstrap sample.

``` r
bootstrap_results = 
  boot_straps |>
  mutate(
    models = map(
      strap_sample,
      \(df) lm(tmax ~ tmin + prcp, data = df)
    ),
    glance_out = map(models, broom::glance),
    tidy_out   = map(models, broom::tidy)
  ) |>
  transmute(
    strap_number,
    r_sq = map_dbl(glance_out, "r.squared"),
    beta_prod = map_dbl(
      tidy_out,
      \(x) {
        b1 = x |> filter(term == "tmin") |> pull(estimate)
        b2 = x |> filter(term == "prcp") |> pull(estimate)
        b1 * b2
      }
    )
  )

bootstrap_results
```

    ## # A tibble: 5,000 × 3
    ##    strap_number  r_sq beta_prod
    ##           <int> <dbl>     <dbl>
    ##  1            1 0.941  -0.00510
    ##  2            2 0.937  -0.00452
    ##  3            3 0.945  -0.00635
    ##  4            4 0.942  -0.00621
    ##  5            5 0.943  -0.00591
    ##  6            6 0.942  -0.00650
    ##  7            7 0.939  -0.00597
    ##  8            8 0.939  -0.00456
    ##  9            9 0.938  -0.00632
    ## 10           10 0.935  -0.00507
    ## # ℹ 4,990 more rows

Turn results into long table and plot the distribution.

``` r
# turn linear regression results of bootstrap samples into long table
boot_long = 
  bootstrap_results |>
  pivot_longer(
    cols = c(r_sq, beta_prod),
    names_to = "quantity",
    values_to = "estimate"
  )

# plot distributions
boot_long |>
  ggplot(aes(x = estimate)) +
  geom_density() +
  facet_grid(~ quantity, scales = "free") +
  labs(
    x = "Bootstrap estimate",
    y = "Density",
    title = "Bootstrap distributions of beta1 * beta2 and R^2"
  )
```

![](p8105_hw6_yg3099_files/figure-gfm/unnamed-chunk-11-1.png)<!-- -->

The bootstrap distribution of $\beta_1\beta_2$ is approximately unimodal
with a slight right skew. Most estimates are between –0.010 and –0.003
and centered near –0.0055. The shape shows moderate variability, but the
estimates remain consistently negative across resamples. This shows a
stable direction for the combined effect of tmin and prcp.

The bootstrap distribution of $R^2$ is tightly concentrated and nearly
symmetric. Estimates lie mostly between 0.93 and 0.95, with a clear peak
around 0.94. The narrow spread indicates little bootstrap variability.
This shows that the overall model fit is highly stable and that tmin and
prcp consistently explain a large proportion of the variability in tmax.

Now the quantiles can also be calculated.

``` r
ci_results = 
  boot_long |>
  group_by(quantity) |>
  summarize(
    ci_lower = quantile(estimate, 0.025),
    ci_upper = quantile(estimate, 0.975)
  )

ci_results
```

    ## # A tibble: 2 × 3
    ##   quantity  ci_lower ci_upper
    ##   <chr>        <dbl>    <dbl>
    ## 1 beta_prod -0.00821 -0.00377
    ## 2 r_sq       0.934    0.947

Using the 2.5% and 97.5% empirical quantiles of the bootstrap samples,
the 95% confidence interval for $\hat{r}^2$ is approximately (-0.00821,
-0.00377).

The 95% confidence interval for $\hat{\beta}_1\hat{\beta}_2$is
approximately (0.934, 0.947).
